%!TEX root = ./graph_reduction.tex
\subsection{Randomisierte Stichproben}

Wir erfassen randomisierte Stichproben, indem wir f"ur einen Graphen $G$ den
    Graphen $G(p)$ konstruieren, in dem jede Kante je mit Wahrscheinlichkeit 
    $p \in [0,1]$ enthalten ist. 
    Den Entscheidungsvorgang, ob eine Kante mit Wahrscheinlichkeit $p$
    in $G(p)$ aufgenommen wird bezeichnen wir im Folgenden als Zufallsexperiment.
    Ferner gilt $V_{G(p)} = V_G$.\\
Uns sollte bewusst sein, dass im Erwartungswert $|E_{G(p)}| = m \cdot p$ Kanten
    in $G(p)$ enthalten sind.
    Dies ist f"ur uns im Kontext des Reduzierens von Kanten zielf"uhrend.\\
    %Ferner ist die Konstruktion von $G(p)$ nicht komplex.\\

\subsubsection{G"ute einer randomisierten Stichprobe}
\label{sec:goodnessRand}

Wir haben festgestellt, dass randomisierte Stichproben uns die M"oglichkeit 
    bieten Kanten elegant zu reduzieren.
    Jedoch haben wir im Teil \hyperref[sec:fEdg]{\textit{2}} zu $F$-leichten/-schweren Kanten gelernt, dass
    manche Kanten nicht im MST/MSF von $G$ vorkommen und es w"unschenswert
    ist m"oglichst wenige $F$-leichte Kanten in $G$ hinsichtlich einer 
    Approximation $F$ des MST/MSF zu haben.\\
Im Folgenden werden wir zeigen, dass die Anzahl von $F_{MSF}$-leichten Kanten in $G$ 
    bez"uglich des MSF $F_{MSF}$ von unserer Stichprobe $G(p)$ 
    nach oben durch einen Erwartungswert von $n/p$ beschr"ankt ist. 
    Diese Annahme folgt aus dem Lemma 10.19 aus dem Buch \cite{randAlg}.\\
Um dies zu beweisen, werden wir zeigen, dass die Annahme von Lemma 10.19 des
    Buches, n"amlich, dass die Zahl $F_{MSF}$-leichter Kanten in $G$ durch
    eine Zufallsvariable mit negativer Binomialverteilung und den Parametern
    $n$, $p$ stochastisch dominiert wird, korrekt ist.
    Dazu lehnen wir uns an den Beweis zum Lemma an.\\
\\
Zun"achst m"ochten wir festlegen, dass im Folgenden alle Kanten aus $G$ nach 
    ihrer Gewichtung aufsteigend sortiert betrachtet werden.
    Dies wird f"ur uns insbesondere dann handlich sein, wenn wir "uber die zu 
    betrachtende Kante wissen m"ochten, ob sie $F$-leicht ist.\\
Nun, da wir uns auf eine Iteration der Kanten festgelegt haben, m"ochten wir 
    $G(p)$ wie "ublich durch das Hinzunehmen der betrachteten Kante mit
    der Wahrscheinlichkeit $p=0,5$ konstruieren.
    W"ahrend wir $G(p)$ konstruieren, k"onnen wir auch simultan, bzw. 
    \glqq online\grqq\ den MSF $F_{MSF}$ von $G(p)$ konstruieren.
    Dies ist beispielsweise durch einen Ansatz, wie den von Kruskal m"oglich, bei
    dem wir genau dann eine Kante $\{u,v\}$ in $F_{MSF}$ aufnehmen, wenn $u,v$
    in verschiedenen verbundenen Komponenten in $F_{MSF}$ liegen. 
    Wobei wir 
    $F_{MSF}$ mit allen Knoten aus $G$ und einer leeren Kantenmenge 
    initialisieren.
    F"ur uns ist dabei interessant, dass dies gleichbedeutend damit ist, dass die Kante 
    $\{u,v\}$
    aus $G$ genau dann $F_{MSF}$-leicht ist, wenn $u$, $v$ in verschieden 
    verbundenen Komponenten in $F_{MSF}$ liegen.
    Die Korrektheit von $F_{MSF}$ als MSF von $G(p)$ folgt aus der Vorsortierung der Kanten,
    bzw. aus der Korrektheit des Algorithmus von Kruskal.\\
Wir k"onnen bereits folgende Eigenschaften zur Konsistenz unseres Verfahrens
    beobachten:\\ 
(i) Ob die zu betrachtende Kante $F_{MSF}$-leicht oder -schwer ist, 
    ist alleinig von den vorhergehenden Zufallsexperimenten abh"angig,\\
(ii) es werden keine Kanten aus $F_{MSF}$ entfernt,\\
(iii) eine Kante ist genau dann nach dem $i$-ten Zufallsexperiment 
    $F_{MSF}$-leicht, wenn sie auch vor dem $i$-ten Zufallsexperiment $F_{MSF}$-leicht
    war.\\
Definieren wir nun den Begriff von Phasen in unserem Zufallsexperiment, um auf
    eine Zufallsvariable zu schlie"sen.
    Die $k$-te Phase unseres Verfahrens beginne, sobald $|E_{F_{MSF}}| = k-1$ Kanten
    vorhanden sind und ende bei $|E_{F_{MSF}}| = k$.
    Wir befassen uns in einer Phase also unter anderem mit der Anzahl von 
    Zufallsexperimenten, die durchgef"uhrt werden m"ussen, 
    bis eine Kante hinzugenommen wird.
    Insbesondere ist die hinzugenommene Kante per Definition unseres Verfahrens
    $F_{MSF}$-leicht. Erinnern wir uns nun an unsere Annahme, so erfassen wir,
    dass $F_{MSF}$-schwere Kanten f"ur unsere Zufallsvariable irrelevant sein
    sollten. Aus diesem Grund ignorieren wir alle $F_{MST}$-schweren Kanten und
    befassen uns in einer Phase nun nur noch mit $F_{MST}$-leichten Kanten und
    der Anzahl von Zufallsexperimenten, bis eine $F_{MST}$-leichte Kante zum 
    ersten Mal hinzugenommen wurde.\\
Nehmen wir nun an, dass wir nach Ablauf unseres Verfahrens $F_{MST}$ mit
    $|E_{F_{MST}}| = s$ erhalten. Aus (i), (ii), (iii) folgt insbesondere, dass bis zum Ende
    der $s$-ten Phase im Erwartungswert pro Phase $1/p$ $F_{MSF}$-leichte
    Kanten betrachtet wurden. Dies entspricht der geometrischen Verteilung mit
    Parameter $p$.
    Da es $F_{MST}$-leichte Kanten geben kann, die in der $s$-ten Phase noch
    betrachtet, aber nicht mehr hinzugenommen wurden,
    m"ussen wir, um eine Zufallsvariable zu 
    erhalten, die unser Verfahren stochastisch dominiert, noch solange weitere 
    Zufallsexperimente f"ur Pseudokanten durchf"uhren, bis zus"atzliche 
    $c=(n-1)-s$ Pseudokanten hinzugenommen wurden.
    Die Zufallsvariable, die die Anzahl von Zufallsexperimenten unter 
    Ber"ucksichtigung der Pseudokanten
    beschreibt sei
    $X_{zexp}$.
    Unser Verfahten unter Zunahme der Pseudokanten dominiert also das Verfahren,
    das w"ahrend der $s$-ten Phase endet,
    Da $s$ maximal gleich $n-1 = s+c$ sein kann.
    Die maximale erwartete Anzahl von $F_{MST}$-leichten Kanten in $G$ ist folglich durch den
    Erwartungswert von $X_{zexp}$ nach oben beschr"ankt.\\
$X_{zexp}$ entspricht der negativen Binomialverteilung, da wir eine Anzahl von
    $n$ Erfolgen je mit Wahrscheinlichkeit $p$ erreichen m"ochten. 
    Folglich ist die erwartete Anzahl von $F_{MST}$-leichten Kanten in $G$ 
    nach oben durch
    einem Erwartungswert von
    $E[X_{zexp}] = n/p$ beschr"ankt.\\
